{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![alt text](https://avatars1.githubusercontent.com/u/59831504?s=400&v=4 \"MtheEPIC User Icon\")](https://github.com/MtheEPIC/KaggleProj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# sns.set_style(\"ticks\", {\"xtick.major.size\": 8, \"ytick.major.size\": 8})\n",
    "sns.axes_style(\"whitegrid\")\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, binarize, label_binarize\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_curve, roc_auc_score, plot_roc_curve, confusion_matrix, classification_report, precision_recall_curve, average_precision_score  \n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, cross_val_predict, cross_validate\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Const And Global Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORES = 3\n",
    "model_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paint():\n",
    "    tmp = train_df.groupby('label').sum()\n",
    "    train_data = np.array(tmp, dtype='float32')\n",
    "\n",
    "    first_image = train_data[0]\n",
    "\n",
    "    first_image = np.array(first_image, dtype='uint8')\n",
    "    pixels = first_image.reshape((28, 28))\n",
    "    import numpy as np; np.random.seed(0)\n",
    "\n",
    "    import seaborn as sns; sns.set()\n",
    "\n",
    "    # uniform_data = np.random.rand(10, 12)\n",
    "    uniform_data = pixels#//500\n",
    "    ax = sns.heatmap(uniform_data)\n",
    "\n",
    "    uniform_data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(true, pred, plot=False):\n",
    "#     model_accuracy = roc_auc_score(true, pred, multi_class=\"ovr\")\n",
    "#     null_accuracy = roc_auc_score(true, true.replace(1, 0))\n",
    "    \n",
    "#     print(\"Null AUC Score: {:.5f}\".format(null_accuracy))\n",
    "#     print(\"Model AUC Score: {:.5f}\".format(model_accuracy))\n",
    "\n",
    "#     if null_accuracy >= model_accuracy:\n",
    "#         print(\"The model isn't effective\")\n",
    "# #         return\n",
    "#     else:\n",
    "#         print(\"The model is better then a 'dumb' model\")\n",
    "    print(\"confusion_matrix:\\n\", confusion_matrix(true, pred))\n",
    "    print(classification_report(true, pred))\n",
    "    if plot:\n",
    "        plot_scores(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(true, pred):\n",
    "    from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "    labels = np.unique(true)\n",
    "\n",
    "    ytest = label_binarize(true, classes=labels)\n",
    "    ypreds = label_binarize(pred, classes=labels)\n",
    "\n",
    "    n_classes = len(labels)\n",
    "    f1_scores = dict()\n",
    "    accuracy_scores = dict()\n",
    "    for i in range(n_classes):\n",
    "        f1_scores[i] = f1_score(ytest[:, i], ypreds[:, i], average='weighted')\n",
    "        accuracy_scores[i] = accuracy_score(ytest[:, i], ypreds[:, i])\n",
    "        plt.scatter(f1_scores[i], accuracy_scores[i], lw=2, label='class {}'.format(i))\n",
    "#         plt.plot(f1_scores[i], accuracy_scores[i], lw=2, label='class {}'.format(i))\n",
    "#     precision = dict()\n",
    "#     recall = dict()\n",
    "#     for i in range(n_classes):\n",
    "#         precision[i] = precision_score(ytest[:, i], ypreds[:, i], average='weighted')\n",
    "#         recall[i] = recall_score(ytest[:, i], ypreds[:, i], average='weighted')\n",
    "\n",
    "\n",
    "    x = list(f1_scores.values())\n",
    "    y = list(accuracy_scores.values())\n",
    "    z = np.polyfit(x, y, 1)\n",
    "    p = np.poly1d(z)\n",
    "    plt.plot(x, p(x), \"r--\")\n",
    "    print(\"y=%.6fx+(%.6f)\"%(z[0],z[1]))\n",
    "    \n",
    "    plt.xlabel(\"f1_scores\")\n",
    "    plt.ylabel(\"accuracy_scores\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title(\"f1_scores vs. accuracy_scores\")\n",
    "    plt.show()\n",
    "    print(labels)\n",
    "    print(accuracy_scores)\n",
    "    print(f1_scores)\n",
    "    return f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_models(model, model_scores):\n",
    "    model_dict.update({model: model_scores})\n",
    "\n",
    "    print(\"Accuracy: {:.2f} (+/- {:.2f})\".format(model_scores['test_score'].mean(), model_scores['test_score'].std() * 2))\n",
    "    print('Train time: {:.2f} seconds (+/- {:.2f}) for a total of {:.2f} seconds'.format(model_scores['fit_time'].mean(), model_scores['fit_time'].std() * 2, model_scores['fit_time'].sum()))\n",
    "    print('Test time: {:.2f} seconds (+/- {:.2f}) for a total of {:.2f} seconds'.format(model_scores['score_time'].mean(), model_scores['score_time'].std() * 2, model_scores['score_time'].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model():\n",
    "    max_score = 0\n",
    "    best_key = None\n",
    "    for key in model_dict:\n",
    "        model_score=model_dict[key]['test_score'].mean()\n",
    "#         model_score = model_dict[key].mean()\n",
    "#         try:   \n",
    "#             model_score=model_dict[key]['test_score'].mean()\n",
    "#         except IndexError: # remove this\n",
    "#             model_score=model_dict[key].mean()\n",
    "        if max_score < model_score:\n",
    "            max_score = model_score\n",
    "            best_key = key\n",
    "    best_model_name = best_key\n",
    "    print('the best model is {}'.format(best_key).split('(')[0], end = ' ')\n",
    "    print('with the score of {}'.format(max_score))\n",
    "    return best_key, max_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/fashion-mnist_train.csv')\n",
    "test_df = pd.read_csv('data/fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()\n",
    "train_df.isnull().sum().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 is t shirt\\\n",
    "1 is trousers\\\n",
    "2 is pullover\\\n",
    "3 is dress\\\n",
    "4 is coat\\\n",
    "5 is sandals\\\n",
    "6 is shirt\\\n",
    "7 is sneaker\\\n",
    "8 is bag\\\n",
    "9 is ankle boots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Columns: 785 entries, label to pixel784\n",
      "dtypes: int64(785)\n",
      "memory usage: 359.3 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Columns: 785 entries, label to pixel784\n",
      "dtypes: int64(785)\n",
      "memory usage: 59.9 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.035333</td>\n",
       "      <td>0.101933</td>\n",
       "      <td>0.247967</td>\n",
       "      <td>0.411467</td>\n",
       "      <td>0.805767</td>\n",
       "      <td>2.198283</td>\n",
       "      <td>5.682000</td>\n",
       "      <td>...</td>\n",
       "      <td>34.625400</td>\n",
       "      <td>23.300683</td>\n",
       "      <td>16.588267</td>\n",
       "      <td>17.869433</td>\n",
       "      <td>22.814817</td>\n",
       "      <td>17.911483</td>\n",
       "      <td>8.520633</td>\n",
       "      <td>2.753300</td>\n",
       "      <td>0.855517</td>\n",
       "      <td>0.07025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.872305</td>\n",
       "      <td>0.094689</td>\n",
       "      <td>0.271011</td>\n",
       "      <td>1.222324</td>\n",
       "      <td>2.452871</td>\n",
       "      <td>4.306912</td>\n",
       "      <td>5.836188</td>\n",
       "      <td>8.215169</td>\n",
       "      <td>14.093378</td>\n",
       "      <td>23.819481</td>\n",
       "      <td>...</td>\n",
       "      <td>57.545242</td>\n",
       "      <td>48.854427</td>\n",
       "      <td>41.979611</td>\n",
       "      <td>43.966032</td>\n",
       "      <td>51.830477</td>\n",
       "      <td>45.149388</td>\n",
       "      <td>29.614859</td>\n",
       "      <td>17.397652</td>\n",
       "      <td>9.356960</td>\n",
       "      <td>2.12587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>170.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label        pixel1        pixel2        pixel3        pixel4  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean       4.500000      0.000900      0.006150      0.035333      0.101933   \n",
       "std        2.872305      0.094689      0.271011      1.222324      2.452871   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        2.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        4.500000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        7.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        9.000000     16.000000     36.000000    226.000000    164.000000   \n",
       "\n",
       "             pixel5        pixel6        pixel7        pixel8        pixel9  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean       0.247967      0.411467      0.805767      2.198283      5.682000   \n",
       "std        4.306912      5.836188      8.215169     14.093378     23.819481   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      227.000000    230.000000    224.000000    255.000000    254.000000   \n",
       "\n",
       "       ...      pixel775      pixel776      pixel777      pixel778  \\\n",
       "count  ...  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean   ...     34.625400     23.300683     16.588267     17.869433   \n",
       "std    ...     57.545242     48.854427     41.979611     43.966032   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...     58.000000      9.000000      0.000000      0.000000   \n",
       "max    ...    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "           pixel779      pixel780      pixel781      pixel782      pixel783  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean      22.814817     17.911483      8.520633      2.753300      0.855517   \n",
       "std       51.830477     45.149388     29.614859     17.397652      9.356960   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      255.000000    255.000000    255.000000    255.000000    255.000000   \n",
       "\n",
       "          pixel784  \n",
       "count  60000.00000  \n",
       "mean       0.07025  \n",
       "std        2.12587  \n",
       "min        0.00000  \n",
       "25%        0.00000  \n",
       "50%        0.00000  \n",
       "75%        0.00000  \n",
       "max      170.00000  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split the training data into train and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(train_df, dtype='float32')\n",
    "test_data = np.array(test_df, dtype='float32')\n",
    "\n",
    "X_train = train_data[:, 1:] / 1\n",
    "y_train = train_data[:, 0]\n",
    "\n",
    "X_test = test_data[:, 1:] / 1#/128#/255\n",
    "y_test = test_data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(random_state=0)\n",
    "pca.fit(X_train)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "x = np.arange(1, len(cumsum)+1)\n",
    "plt.plot(x, cumsum)\n",
    "plt.grid(True)\n",
    "plt.title('Variance as Dimensions Functions')\n",
    "plt.xlabel('Dimensions')\n",
    "plt.ylabel('Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of vectors after pca is 84\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(random_state=0, n_components=0.90)\n",
    "pca.fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "d = len(pca.singular_values_)\n",
    "print('the number of vectors after pca is {}'.format(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_image = X_train[0]\n",
    "\n",
    "first_image = np.array(first_image, dtype='uint8')\n",
    "pixels = first_image.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run The Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77 (+/- 0.01)\n",
      "Train time: 0.07 seconds (+/- 0.01) for a total of 0.74 seconds\n",
      "Test time: 0.08 seconds (+/- 0.01) for a total of 0.80 seconds\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "\n",
    "# gnb.fit(X_train_pca, y_train)\n",
    "# predictions = gnb.predict(X_test_pca)\n",
    "# evaluate(y_test, predictions)\n",
    "\n",
    "gnb_scores = cross_validate(gnb, X_train_pca, y_train, cv=10)\n",
    "score_models(gnb, gnb_scores)\n",
    "\n",
    "pred = cross_val_predict(gnb, X_train_pca, y_train, cv=10, n_jobs=CORES)\n",
    "evaluate(y_train, pred, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnb = MultinomialNB()\n",
    "# mnb.fit(X_train_pca, y_train)\n",
    "# predictions = mnb.predict(X_test_pca)\n",
    "# evaluate(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=0, max_depth=None, n_estimators=100, n_jobs=CORES)\n",
    "\n",
    "# scores = cross_val_score(rf, X_train_pca, y_train, cv=10, scoring='neg_mean_squared_error')\n",
    "# rf_score = np.sqrt(-scores)\n",
    "rf_scores = cross_validate(rf, X_train_pca, y_train, cv=10, n_jobs=CORES)\n",
    "\n",
    "# model_dict.update({\"RandomForestClassifier\": rf_score})\n",
    "\n",
    "# print(\"Accuracy: %0.2f (+/- %0.2f)\" % (rf_score.mean(), rf_score.std() * 2))\n",
    "\n",
    "score_models(rf, rf_scores)\n",
    "\n",
    "pred = cross_val_predict(rf, X_train_pca, y_train, cv=10, n_jobs=CORES)\n",
    "evaluate(y_train, pred, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets find the optimum K \n",
    "k_max = 15\n",
    "k_min = 1\n",
    "err_rate = []\n",
    "for i in range(k_min, k_max+1):\n",
    "    k = KNeighborsClassifier(n_neighbors=i, n_jobs=CORES)\n",
    "#     k.fit(X_train_pca, y_train)\n",
    "#     pred_i = k.predict(X_test_pca)\n",
    "#     err_rate.append(np.mean(pred_i != y_test))\n",
    "    scores = cross_validate(k, X_train_pca, y_train, cv=10, n_jobs=CORES)['test_score']\n",
    "    if scores.std() > 0.5:\n",
    "        err_rate.append(0)\n",
    "    else:\n",
    "        err_rate.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(k_min, k_max+1), err_rate)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = err_rate.index(max(err_rate)) + 1\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = KNeighborsClassifier(n_neighbors=index, n_jobs=CORES)\n",
    "k_scores = cross_validate(k, X_train_pca, y_train, cv=10, n_jobs=CORES)\n",
    "score_models(k, k_scores)\n",
    "\n",
    "pred = cross_val_predict(k, X_train_pca, y_train, cv=10, n_jobs=CORES)\n",
    "evaluate(y_train, pred, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=0, n_jobs=CORES)#, solver='lbfgs', penalty='l2')\n",
    "lr_scores = cross_validate(lr, X_train_pca, y_train, cv=10, n_jobs=CORES)\n",
    "score_models(lr, lr_scores)\n",
    "\n",
    "pred = cross_val_predict(lr, X_train_pca, y_train, cv=10, n_jobs=CORES)\n",
    "evaluate(y_train, pred, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(random_state=0, max_iter=500)\n",
    "\n",
    "svc_scores = cross_validate(svc, X_train_pca, y_train, cv=10, n_jobs=CORES)\n",
    "score_models(svc, svc_scores)\n",
    "\n",
    "pred = cross_val_predict(svc, X_train_pca, y_train, cv=10, n_jobs=CORES)\n",
    "evaluate(y_train, pred, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(random_state=0)\n",
    "dtc_scores = cross_validate(dtc, X_train_pca, y_train, cv=10, n_jobs=CORES)\n",
    "score_models(dtc, dtc_scores)\n",
    "\n",
    "pred = cross_val_predict(dtc, X_train_pca, y_train, cv=10, n_jobs=CORES)\n",
    "evaluate(y_train, pred, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gb = GradientBoostingClassifier(random_state=0)\n",
    "# gb_scores = cross_validate(gb, X_train_pca, y_train, cv=10, n_jobs=CORES)\n",
    "# score_models(gb, gb_scores)\n",
    "\n",
    "# pred = cross_val_predict(gb, X_train_pca, y_train, cv=10, n_jobs=CORES)\n",
    "# evaluate(y_train, pred, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, best_model_score = find_best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_estimetor = best_model\n",
    "adb = AdaBoostClassifier(base_estimetor, random_state=0)\n",
    "adb_scores = cross_validate(adb, X_train_pca, y_train, cv=10, n_jobs=CORES)\n",
    "\n",
    "pred = cross_val_predict(adb_scores, X_train_pca, y_train, cv=10, n_jobs=CORES)\n",
    "evaluate(y_train, pred, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check if the model was improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if adb_scores['test_score'].mean() > best_model_score:\n",
    "    best_model = adb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test The Model On The Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X_train_pca, y_train)\n",
    "predictions = best_model.predict(X_test_pca)\n",
    "evaluate(y_test, predictions, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run without pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X_train, y_train)\n",
    "predictions = best_model.predict(X_test)\n",
    "evaluate(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# labels = [0, 1, 2, 3,4,5,6,7,8,9]\n",
    "# ytest = label_binarize(y_test, classes=labels)\n",
    "# ypreds = label_binarize(predictions, classes=labels)\n",
    "\n",
    "# roc_auc_score(ytest, ypreds, average='macro',multi_class='ovo')\n",
    "# # plot_roc_curve(best_model, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # precision recall curve\n",
    "# # precision = dict()\n",
    "# # recall = dict()\n",
    "# # for i in range(n_classes):\n",
    "# #     precision[i], recall[i], _ = precision_recall_curve(y_test[:, i],\n",
    "# #                                                         y_score[:, i]))\n",
    "# #     plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\n",
    "# n_classes = len(labels)\n",
    "# roc_scores = [0, 1, 2, 3,4,5,6,7,8,9]\n",
    "# for i in range(n_classes):\n",
    "#     roc_scores[i] = roc_auc_score(ytest[:, i], ypreds[:, i], average='macro',multi_class='ovo')\n",
    "#     plt.scatter(labels[i], roc_scores[i], lw=2, label='class {}'.format(i))\n",
    "\n",
    "# # plt.plot(labels, roc_scores, lw=2, label='class {}'.format(i))\n",
    "# plt.xlabel(\"recall\")\n",
    "# plt.ylabel(\"precision\")\n",
    "# plt.legend(loc=\"best\")\n",
    "# plt.title(\"precision vs. recall curve\")\n",
    "# plt.show()\n",
    "\n",
    "# for i in range(n_classes):\n",
    "#     print('{} {}'.format(labels[i], roc_scores[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gnb = GaussianNB()\n",
    "# # \n",
    "# # gnb.fit(X_train_pca, y_train)\n",
    "# # predictions = gnb.predict(X_test_pca)\n",
    "# # evaluate(y_test, predictions)\n",
    "\n",
    "# gnb_scores = cross_validate(gnb, X_train_pca, y_train, cv=10)\n",
    "# score_models('GaussianNB', gnb_scores)\n",
    "\n",
    "# pred = cross_val_predict(gnb, X_train_pca, y_train, cv=10, n_jobs=CORES)\n",
    "\n",
    "# print(accuracy_score(y_train, pred))\n",
    "\n",
    "# evaluate(y_train, pred, plot=True)\n",
    "# # print(f1_score(y_train, pred, average='macro'))\n",
    "\n",
    "# # tmp = plot_scores(y_train, pred)\n",
    "# # tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate(y_test, predictions)\n",
    "\n",
    "# ytest = label_binarize(y_test, classes=labels)\n",
    "# ypreds = label_binarize(predictions, classes=labels)\n",
    "\n",
    "# # scoring = 'average_precision'\n",
    "# fpr, tpr, thresholds = roc_curve(ytest, ypreds)\n",
    "# scores = []\n",
    "# for x in thresholds:\n",
    "#     predictions_class = binarize([predictions], x)[0]\n",
    "#     scores.append(average_precision_score(y_test, predictions_class))\n",
    "# scores = np.array(scores)\n",
    "# index = np.argmax(scores) \n",
    "\n",
    "\n",
    "# scores = []\n",
    "# thresholds = np.arange(0, 1, 0.01)\n",
    "# for x in thresholds:\n",
    "#     predictions_class = binarize([predictions], x)[0]\n",
    "#     scores.append(accuracy_score(y_test, predictions_class))\n",
    "# scores = np.array(scores)\n",
    "# index = np.argmax(scores) \n",
    "# predictions_class = binarize([predictions], thresholds[index])[0]\n",
    "# evaluate(y_test, predictions_class)\n",
    "\n",
    "\n",
    "# thresholds[index]\n",
    "# predictions\n",
    "# # binarize([predictions], 0.5)[0]\n",
    "# y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Predict test_y values and probabilities based on fitted logistic \n",
    "# # regression model\n",
    "\n",
    "# pred_y=best_model.predict(X_test_pca) \n",
    "# # pred_y = predictions\n",
    "\n",
    "# probs_y=best_model.predict_proba(X_test_pca) \n",
    "# #   # probs_y is a 2-D array of probability of being labeled as 0 (first \n",
    "# #   column of \n",
    "# #   array) vs 1 (2nd column in array)\n",
    "\n",
    "# from sklearn.metrics import precision_recall_curve\n",
    "# precision, recall, thresholds = precision_recall_curve(y_test, probs_y[:, \n",
    "# 1]) \n",
    "#    #retrieve probability of being 1(in second column of probs_y)\n",
    "# pr_auc = metrics.auc(recall, precision)\n",
    "\n",
    "# plt.title(\"Precision-Recall vs Threshold Chart\")\n",
    "# plt.plot(thresholds, precision[: -1], \"b--\", label=\"Precision\")\n",
    "# plt.plot(thresholds, recall[: -1], \"r--\", label=\"Recall\")\n",
    "# plt.ylabel(\"Precision, Recall\")\n",
    "# plt.xlabel(\"Threshold\")\n",
    "# plt.legend(loc=\"lower left\")\n",
    "# plt.ylim([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
